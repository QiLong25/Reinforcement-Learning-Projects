{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZWsnEMjaMR0"
      },
      "source": [
        "**Welcome to the first programming assignment for CS 443 RL!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfPe-_9iawIJ"
      },
      "source": [
        "This assignment will get you familiar with the OpenAI gym environment and estimation via sampling trajectories.\n",
        "\n",
        "**For submission: Please convert the iPython notebook (containing both outputs and your code) into pdf, and append the pdf to that of your written work.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEvS3FEgWxc6",
        "outputId": "22761fb3-1345-48f6-9bd9-627c6221aa27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25.2\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "print(gym.__version__) # should be 0.25.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMgTMDy6OS2e"
      },
      "source": [
        "We will be playing on the Cartpole environment. As the title suggests, the task in this environment is to balance a pole on top of a cart. The official description of the environment from the Gym website (https://www.gymlibrary.dev/) is:\n",
        "\n",
        "> This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in \"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\". A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart.\n",
        "\n",
        "The environment is loaded as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E9zqEYpOd6b",
        "outputId": "1f4a829a-0f15-42fa-e8a3-1951d73f2dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(2)\n",
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('CartPole-v1') # ignore the warning\n",
        "env.reset() # must reset the environment before interacting with it\n",
        "print (env.action_space) # show the action space, which has 2 actions\n",
        "print (env.observation_space) # show the state (observation) space, which is a\n",
        "                              # 4-dimensional vector with components of\n",
        "                              # [position, velocity,\n",
        "                              #  pole angle, pole velocity at tip]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p-aroLbSNHc"
      },
      "source": [
        "More information can be found on the following page: https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
        "\n",
        "Here is the policy that you will be using (which just acts randomly with a uniform distribution)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_Tj6_VrSSW_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce7f941-6f6e-4a84-d366-703d52d27ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.04481104  0.04328649 -0.01001667  0.04731801]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "def policy_unif(s):\n",
        "  a = env.action_space.sample()\n",
        "  return a\n",
        "s0 = env.reset()\n",
        "print(s0)\n",
        "print(policy_unif(s0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gGjIQIkWKEw"
      },
      "source": [
        " You can interact with the environment with the `env.step()` function, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFN1pJUaWOqm",
        "outputId": "15aa1762-636c-4989-ab6c-2183967adb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.04394531  0.23855063 -0.00907031 -0.24850836]\n",
            "1.0\n",
            "False\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "observation, reward, done, info = env.step(env.action_space.sample())\n",
        "print(observation)  # the state that you transition to after taking the action\n",
        "print(reward)       # immediate reward\n",
        "print(done)         # a boolean flag of whether the episode has terminated\n",
        "print(info)         # not useful for this assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg5RqiBMQKKw"
      },
      "source": [
        "**Q1**: Write a method called `collect_trajectory(policy)` which collects one trajectory for an episode in the Cartpole environment. Your method should take as input the policy (`policy`) and output a list of the form $(s_0, a_0, r_0, s_1, a_1, r_1, \\dots, s_T, a_T, r_T)$, where $T$ is the length of the episode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Ob_sqnGGQlJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a39fe26-6489-4cb4-b61f-414c5abc99a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([-0.0460774 ,  0.00483577,  0.01353033,  0.02554428], dtype=float32), 1, 1.0, array([-0.04598068,  0.1997611 ,  0.01404121, -0.26283914], dtype=float32), 1, 1.0, array([-0.04198546,  0.39467984,  0.00878443, -0.55106044], dtype=float32), 1, 1.0, array([-0.03409187,  0.58967733, -0.00223678, -0.8409628 ], dtype=float32), 0, 1.0, array([-0.02229832,  0.39458597, -0.01905604, -0.5489841 ], dtype=float32), 1, 1.0, array([-0.0144066 ,  0.58997035, -0.03003572, -0.84760964], dtype=float32), 1, 1.0, array([-0.00260719,  0.78548884, -0.04698791, -1.1495843 ], dtype=float32), 1, 1.0, array([ 0.01310258,  0.9811915 , -0.0699796 , -1.4566237 ], dtype=float32), 1, 1.0, array([ 0.03272641,  1.177099  , -0.09911207, -1.7703228 ], dtype=float32), 1, 1.0, array([ 0.05626839,  1.37319   , -0.13451852, -2.092107  ], dtype=float32), 1, 1.0, array([ 0.0837322 ,  1.5693871 , -0.17636067, -2.4231734 ], dtype=float32), 0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# generate a trajectory in the environment\n",
        "# use env.step to roll out a trajectory until the episode terminates\n",
        "# output a list of the form [s0, a0, r0, s1, a1, ..., sT, aT, rT]\n",
        "# (s_{T+1} is the terminal state)\n",
        "def collect_trajectory(policy):\n",
        "  s0 = env.reset() #reset the environment\n",
        "  # YOUR CODE HERE\n",
        "  trajectory = []       # list to return\n",
        "  done = False\n",
        "  state = s0\n",
        "  while done == False:\n",
        "    trajectory.append(state)\n",
        "    action = policy(s0)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    trajectory.append(action)\n",
        "    trajectory.append(reward)\n",
        "  return trajectory\n",
        "traj = collect_trajectory(policy_unif)\n",
        "print(collect_trajectory(policy_unif))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwwP8NzVRYL6"
      },
      "source": [
        "**Q2**: Write a method called `compute_return(traj, gamma)`, which takes as input one trajectory (`traj`) of the form given by `collect_trajectory` in Q1 and a discount factor (`gamma`), and calculates the random return of the trajectory, i.e., $r_0 + \\gamma r_1 + \\gamma^2 r_2 + \\dots + \\gamma^T r_T$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "3DBJBZhqRhwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69340947-c1c6-4051-874a-774a622c540b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9999980926513672\n"
          ]
        }
      ],
      "source": [
        "def compute_return(traj, gamma):\n",
        "  # YOUR CODE HERE\n",
        "  idx = 2       # r0 index in traj\n",
        "  try:\n",
        "    result = traj[idx]      # total reward to return\n",
        "    idx += 3\n",
        "  except:\n",
        "    result = 0\n",
        "    return result\n",
        "  factor = gamma\n",
        "  while idx < len(traj):\n",
        "    result += traj[idx] * factor\n",
        "    idx += 3\n",
        "    factor *= gamma\n",
        "\n",
        "  return result\n",
        "print(compute_return(traj, 0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw1Yvbw05uPP"
      },
      "source": [
        "**Q3**: Collect $150$ trajectories starting from the initial states given by `env.reset()` and compute the random return of each trajectory, using the given policy and $\\gamma = 0.99$.\n",
        "\n",
        "1.   Plot a histogram of these returns.\n",
        "2.   Estimate the mean of these returns, and give your result in the form of $X \\pm Y$, where $X$ is the estimated mean and $Y$ is twice the standard error of your mean estimate, which corresponds to a $95\\%$ confidence interval.\n",
        "\n",
        "Remark: The mean is also an estimate of the value function of $\\pi$ for the initial state, often referred to as a \"Monte-Carlo\" estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "sYNjz6fS9Vaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "cd69e316-2cf6-496e-818d-370e6d8f5efe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgg0lEQVR4nO3df2xV9f3H8dfF0suv3osttLcNt1CBgVjKYnXlRseQVkolBKQm80dicQSjuxBLs4ld/LFuLu0wUSTBaqYDTagsGMGgEYbVXmIsDOoawM1GGgg10LKx9N5S1ktDz/ePhfv10vLjtrefy708H8lJuOec3vv+5Mz1mfurNsuyLAEAABgyItYDAACAmwvxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOSYj3A5fr6+nTq1CmlpKTIZrPFehwAAHAdLMtSV1eXsrKyNGLE1Z/buOHi49SpU3K73bEeAwAADEJbW5smTZp01XNuuPhISUmR9L/hHQ5HjKcBAADXIxAIyO12h36PX80NFx+XXmpxOBzEBwAAceZ63jLBG04BAIBRQ4qPmpoa2Ww2lZeXh/b19PTI6/UqLS1N48aNU2lpqTo6OoY6JwAASBCDjo+DBw/qrbfeUl5eXtj+tWvXateuXdq+fbt8Pp9OnTql5cuXD3lQAACQGAYVH+fOndNjjz2mP/3pT7r11ltD+/1+v9555x29+uqrWrBggfLz87V582Z99dVX2r9/f9SGBgAA8WtQ8eH1erV48WIVFRWF7W9qalJvb2/Y/pkzZyo7O1uNjY0D3lcwGFQgEAjbAABA4or40y7btm3T119/rYMHD/Y71t7eruTkZI0fPz5sf0ZGhtrb2we8v+rqalVVVUU6BgAAiFMRPfPR1tamZ555Rlu3btWoUaOiMkBlZaX8fn9oa2tri8r9AgCAG1NE8dHU1KQzZ87ozjvvVFJSkpKSkuTz+bRx40YlJSUpIyNDFy5cUGdnZ9jPdXR0yOVyDXifdrs99J0efLcHAACJL6KXXQoLC3XkyJGwfU888YRmzpypdevWye12a+TIkaqvr1dpaakkqaWlRSdPnpTH44ne1AAAIG5FFB8pKSnKzc0N2zd27FilpaWF9q9cuVIVFRVKTU2Vw+HQmjVr5PF4NHfu3OhNDQAA4lbUv179tdde04gRI1RaWqpgMKji4mK98cYb0X4YAAAQp2yWZVmxHuKHAoGAnE6n/H4/7/8AACBORPL7m7/tAgAAjCI+AACAUVF/zweib8pzn8R6hIidqFkc6xEAADconvkAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAURHFR21trfLy8uRwOORwOOTxePTpp5+Gjs+fP182my1se+qpp6I+NAAAiF9JkZw8adIk1dTUaPr06bIsS++++66WLl2qv//977rjjjskSatWrdLvfve70M+MGTMmuhMDAIC4FlF8LFmyJOz2H/7wB9XW1mr//v2h+BgzZoxcLlf0JgQAAAll0O/5uHjxorZt26bu7m55PJ7Q/q1bt2rChAnKzc1VZWWlzp8/f9X7CQaDCgQCYRsAAEhcET3zIUlHjhyRx+NRT0+Pxo0bpx07dmjWrFmSpEcffVSTJ09WVlaWDh8+rHXr1qmlpUUffvjhFe+vurpaVVVVg18BAACIKzbLsqxIfuDChQs6efKk/H6/PvjgA7399tvy+XyhAPmhzz//XIWFhTp27JimTp064P0Fg0EFg8HQ7UAgILfbLb/fL4fDEeFyEtOU5z6J9QgRO1GzONYjAAAMCgQCcjqd1/X7O+JnPpKTkzVt2jRJUn5+vg4ePKjXX39db731Vr9zCwoKJOmq8WG322W32yMdAwAAxKkhf89HX19f2DMXP9Tc3CxJyszMHOrDAACABBHRMx+VlZUqKSlRdna2urq6VFdXp4aGBu3Zs0etra2qq6vTAw88oLS0NB0+fFhr167VvHnzlJeXN1zzAwCAOBNRfJw5c0aPP/64Tp8+LafTqby8PO3Zs0f333+/2tra9Nlnn2nDhg3q7u6W2+1WaWmpnn/++eGaHQAAxKGI4uOdd9654jG32y2fzzfkgQAAQGLjb7sAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGBURPFRW1urvLw8ORwOORwOeTweffrpp6HjPT098nq9SktL07hx41RaWqqOjo6oDw0AAOJXRPExadIk1dTUqKmpSYcOHdKCBQu0dOlSffPNN5KktWvXateuXdq+fbt8Pp9OnTql5cuXD8vgAAAgPtksy7KGcgepqal65ZVX9NBDD2nixImqq6vTQw89JEn69ttvdfvtt6uxsVFz5869rvsLBAJyOp3y+/1yOBxDGS1hTHnuk1iPELETNYtjPQIAwKBIfn8P+j0fFy9e1LZt29Td3S2Px6Ompib19vaqqKgodM7MmTOVnZ2txsbGwT4MAABIMEmR/sCRI0fk8XjU09OjcePGaceOHZo1a5aam5uVnJys8ePHh52fkZGh9vb2K95fMBhUMBgM3Q4EApGOBAAA4kjEz3zMmDFDzc3NOnDggJ5++mmVlZXpH//4x6AHqK6ultPpDG1ut3vQ9wUAAG58EcdHcnKypk2bpvz8fFVXV2vOnDl6/fXX5XK5dOHCBXV2doad39HRIZfLdcX7q6yslN/vD21tbW0RLwIAAMSPIX/PR19fn4LBoPLz8zVy5EjV19eHjrW0tOjkyZPyeDxX/Hm73R766O6lDQAAJK6I3vNRWVmpkpISZWdnq6urS3V1dWpoaNCePXvkdDq1cuVKVVRUKDU1VQ6HQ2vWrJHH47nuT7oAAIDEF1F8nDlzRo8//rhOnz4tp9OpvLw87dmzR/fff78k6bXXXtOIESNUWlqqYDCo4uJivfHGG8MyOAAAiE9D/p6PaON7Pvrjez4AADc6I9/zAQAAMBjEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjkmI9ABLTlOc+ifUIETtRszjWIwDATYFnPgAAgFHEBwAAMIr4AAAARkUUH9XV1br77ruVkpKi9PR0LVu2TC0tLWHnzJ8/XzabLWx76qmnojo0AACIXxHFh8/nk9fr1f79+7V371719vZq4cKF6u7uDjtv1apVOn36dGhbv359VIcGAADxK6JPu+zevTvs9pYtW5Senq6mpibNmzcvtH/MmDFyuVzRmRAAACSUIb3nw+/3S5JSU1PD9m/dulUTJkxQbm6uKisrdf78+aE8DAAASCCD/p6Pvr4+lZeX65577lFubm5o/6OPPqrJkycrKytLhw8f1rp169TS0qIPP/xwwPsJBoMKBoOh24FAYLAjAQCAODDo+PB6vTp69Ki+/PLLsP1PPvlk6N+zZ89WZmamCgsL1draqqlTp/a7n+rqalVVVQ12jIjF45dfAQCQSAb1ssvq1av18ccf64svvtCkSZOuem5BQYEk6dixYwMer6yslN/vD21tbW2DGQkAAMSJiJ75sCxLa9as0Y4dO9TQ0KCcnJxr/kxzc7MkKTMzc8Djdrtddrs9kjEAAEAciyg+vF6v6urq9NFHHyklJUXt7e2SJKfTqdGjR6u1tVV1dXV64IEHlJaWpsOHD2vt2rWaN2+e8vLyhmUBAAAgvkQUH7W1tZL+90ViP7R582atWLFCycnJ+uyzz7RhwwZ1d3fL7XartLRUzz//fNQGBgAA8S3il12uxu12y+fzDWkgAACQ2PjbLgAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgVER/WA5IZFOe+yTWI0TsRM3iWI8AABHjmQ8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAqIjio7q6WnfffbdSUlKUnp6uZcuWqaWlJeycnp4eeb1epaWlady4cSotLVVHR0dUhwYAAPErovjw+Xzyer3av3+/9u7dq97eXi1cuFDd3d2hc9auXatdu3Zp+/bt8vl8OnXqlJYvXx71wQEAQHxKiuTk3bt3h93esmWL0tPT1dTUpHnz5snv9+udd95RXV2dFixYIEnavHmzbr/9du3fv19z586N3uQAACAuDek9H36/X5KUmpoqSWpqalJvb6+KiopC58ycOVPZ2dlqbGwc8D6CwaACgUDYBgAAEteg46Ovr0/l5eW65557lJubK0lqb29XcnKyxo8fH3ZuRkaG2tvbB7yf6upqOZ3O0OZ2uwc7EgAAiAODjg+v16ujR49q27ZtQxqgsrJSfr8/tLW1tQ3p/gAAwI0tovd8XLJ69Wp9/PHH2rdvnyZNmhTa73K5dOHCBXV2doY9+9HR0SGXyzXgfdntdtnt9sGMAQAA4lBEz3xYlqXVq1drx44d+vzzz5WTkxN2PD8/XyNHjlR9fX1oX0tLi06ePCmPxxOdiQEAQFyL6JkPr9eruro6ffTRR0pJSQm9j8PpdGr06NFyOp1auXKlKioqlJqaKofDoTVr1sjj8fBJFwAAICnC+KitrZUkzZ8/P2z/5s2btWLFCknSa6+9phEjRqi0tFTBYFDFxcV64403ojIsAACIfxHFh2VZ1zxn1KhR2rRpkzZt2jTooQAAQOLib7sAAACjiA8AAGDUoD5qC+DGMOW5T2I9QsRO1CyO9QgAYoxnPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGBUxPGxb98+LVmyRFlZWbLZbNq5c2fY8RUrVshms4VtixYtita8AAAgzkUcH93d3ZozZ442bdp0xXMWLVqk06dPh7b3339/SEMCAIDEkRTpD5SUlKikpOSq59jtdrlcrkEPBQAAEtewvOejoaFB6enpmjFjhp5++mmdPXv2iucGg0EFAoGwDQAAJK6ox8eiRYv03nvvqb6+Xn/84x/l8/lUUlKiixcvDnh+dXW1nE5naHO73dEeCQAA3EAiftnlWh5++OHQv2fPnq28vDxNnTpVDQ0NKiws7Hd+ZWWlKioqQrcDgQABAgBAAhv2j9redtttmjBhgo4dOzbgcbvdLofDEbYBAIDENezx8f333+vs2bPKzMwc7ocCAABxIOKXXc6dOxf2LMbx48fV3Nys1NRUpaamqqqqSqWlpXK5XGptbdWzzz6radOmqbi4OKqDAwCA+BRxfBw6dEj33Xdf6Pal92uUlZWptrZWhw8f1rvvvqvOzk5lZWVp4cKF+v3vfy+73R69qQEAQNyKOD7mz58vy7KueHzPnj1DGggAACQ2/rYLAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGRRwf+/bt05IlS5SVlSWbzaadO3eGHbcsSy+++KIyMzM1evRoFRUV6bvvvovWvAAAIM5FHB/d3d2aM2eONm3aNODx9evXa+PGjXrzzTd14MABjR07VsXFxerp6RnysAAAIP4lRfoDJSUlKikpGfCYZVnasGGDnn/+eS1dulSS9N577ykjI0M7d+7Uww8/PLRpAQBA3Ivqez6OHz+u9vZ2FRUVhfY5nU4VFBSosbFxwJ8JBoMKBAJhGwAASFxRjY/29nZJUkZGRtj+jIyM0LHLVVdXy+l0hja32x3NkQAAwA0m5p92qayslN/vD21tbW2xHgkAAAyjqMaHy+WSJHV0dITt7+joCB27nN1ul8PhCNsAAEDiimp85OTkyOVyqb6+PrQvEAjowIED8ng80XwoAAAQpyL+tMu5c+d07Nix0O3jx4+rublZqampys7OVnl5uV5++WVNnz5dOTk5euGFF5SVlaVly5ZFc24AABCnIo6PQ4cO6b777gvdrqiokCSVlZVpy5YtevbZZ9Xd3a0nn3xSnZ2duvfee7V7926NGjUqelMDAIC4ZbMsy4r1ED8UCATkdDrl9/uH5f0fU577JOr3CeD6nahZHOsRAAyDSH5/x/zTLgAA4OZCfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjEqK9QAAcKOb8twnsR5hUE7ULI71CMCAeOYDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFFRj4/f/va3stlsYdvMmTOj/TAAACBOJQ3Hnd5xxx367LPP/v9BkoblYQAAQBwalipISkqSy+UajrsGAABxblje8/Hdd98pKytLt912mx577DGdPHnyiucGg0EFAoGwDQAAJK6oP/NRUFCgLVu2aMaMGTp9+rSqqqr005/+VEePHlVKSkq/86urq1VVVRXtMQDcoKY890msRwAQYzbLsqzhfIDOzk5NnjxZr776qlauXNnveDAYVDAYDN0OBAJyu93y+/1yOBxRn4f/4wNwszhRszjWI+AmEggE5HQ6r+v397C/E3T8+PH60Y9+pGPHjg143G63y263D/cYAADgBjHs3/Nx7tw5tba2KjMzc7gfCgAAxIGox8evfvUr+Xw+nThxQl999ZUefPBB3XLLLXrkkUei/VAAACAORf1ll++//16PPPKIzp49q4kTJ+ree+/V/v37NXHixGg/FAAAiENRj49t27ZF+y4BAEAC4W+7AAAAo4gPAABgFH90BQASVDx+rxHfTXJz4JkPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMSor1AAAAXDLluU9iPcJN4UTN4pg+Ps98AAAAo4gPAABgFPEBAACMIj4AAIBRwxYfmzZt0pQpUzRq1CgVFBTob3/723A9FAAAiCPDEh9/+ctfVFFRoZdeeklff/215syZo+LiYp05c2Y4Hg4AAMSRYYmPV199VatWrdITTzyhWbNm6c0339SYMWP05z//eTgeDgAAxJGof8/HhQsX1NTUpMrKytC+ESNGqKioSI2Njf3ODwaDCgaDodt+v1+SFAgEoj2aJKkveH5Y7hcAgHgxHL9jL92nZVnXPDfq8fHvf/9bFy9eVEZGRtj+jIwMffvtt/3Or66uVlVVVb/9brc72qMBAABJzg3Dd99dXV1yOp1XPSfm33BaWVmpioqK0O2+vj795z//UVpammw2WwwnCxcIBOR2u9XW1iaHwxHrcYbNzbBO1pg4boZ1ssbEkejrtCxLXV1dysrKuua5UY+PCRMm6JZbblFHR0fY/o6ODrlcrn7n2+122e32sH3jx4+P9lhR43A4EvJ/NJe7GdbJGhPHzbBO1pg4Enmd13rG45Kov+E0OTlZ+fn5qq+vD+3r6+tTfX29PB5PtB8OAADEmWF52aWiokJlZWW666679JOf/EQbNmxQd3e3nnjiieF4OAAAEEeGJT5+/vOf61//+pdefPFFtbe368c//rF2797d702o8cRut+ull17q9xJRorkZ1skaE8fNsE7WmDhulnVeD5t1PZ+JAQAAiBL+tgsAADCK+AAAAEYRHwAAwCjiAwAAGEV8XGbfvn1asmSJsrKyZLPZtHPnzrDjlmXpxRdfVGZmpkaPHq2ioiJ99913sRl2kK61xhUrVshms4VtixYtis2wg1RdXa27775bKSkpSk9P17Jly9TS0hJ2Tk9Pj7xer9LS0jRu3DiVlpb2+3K8G931rHP+/Pn9rudTTz0Vo4kjV1tbq7y8vNAXM3k8Hn366aeh44lwHa+1xni/hgOpqamRzWZTeXl5aF8iXMvLDbTORLyekSI+LtPd3a05c+Zo06ZNAx5fv369Nm7cqDfffFMHDhzQ2LFjVVxcrJ6eHsOTDt611ihJixYt0unTp0Pb+++/b3DCofP5fPJ6vdq/f7/27t2r3t5eLVy4UN3d3aFz1q5dq127dmn79u3y+Xw6deqUli9fHsOpI3c965SkVatWhV3P9evXx2jiyE2aNEk1NTVqamrSoUOHtGDBAi1dulTffPONpMS4jtdaoxTf1/ByBw8e1FtvvaW8vLyw/YlwLX/oSuuUEut6DoqFK5Jk7dixI3S7r6/Pcrlc1iuvvBLa19nZadntduv999+PwYRDd/kaLcuyysrKrKVLl8ZknuFy5swZS5Ll8/ksy/rfdRs5cqS1ffv20Dn//Oc/LUlWY2NjrMYcssvXaVmW9bOf/cx65plnYjfUMLj11lutt99+O2Gvo2X9/xotK7GuYVdXlzV9+nRr7969YetKtGt5pXVaVmJdz8HimY8IHD9+XO3t7SoqKgrtczqdKigoUGNjYwwni76Ghgalp6drxowZevrpp3X27NlYjzQkfr9fkpSamipJampqUm9vb9i1nDlzprKzs+P6Wl6+zku2bt2qCRMmKDc3V5WVlTp//nwsxhuyixcvatu2beru7pbH40nI63j5Gi9JlGvo9Xq1ePHisGsmJd5/k1da5yWJcj0HK+Z/1TaetLe3S1K/b2rNyMgIHUsEixYt0vLly5WTk6PW1lb95je/UUlJiRobG3XLLbfEeryI9fX1qby8XPfcc49yc3Ml/e9aJicn9/sjhvF8LQdapyQ9+uijmjx5srKysnT48GGtW7dOLS0t+vDDD2M4bWSOHDkij8ejnp4ejRs3Tjt27NCsWbPU3NycMNfxSmuUEuMaStK2bdv09ddf6+DBg/2OJdJ/k1dbp5Q413MoiA/08/DDD4f+PXv2bOXl5Wnq1KlqaGhQYWFhDCcbHK/Xq6NHj+rLL7+M9SjD6krrfPLJJ0P/nj17tjIzM1VYWKjW1lZNnTrV9JiDMmPGDDU3N8vv9+uDDz5QWVmZfD5frMeKqiutcdasWQlxDdva2vTMM89o7969GjVqVKzHGTbXs85EuJ5DxcsuEXC5XJLU793XHR0doWOJ6LbbbtOECRN07NixWI8SsdWrV+vjjz/WF198oUmTJoX2u1wuXbhwQZ2dnWHnx+u1vNI6B1JQUCBJcXU9k5OTNW3aNOXn56u6ulpz5szR66+/nlDX8UprHEg8XsOmpiadOXNGd955p5KSkpSUlCSfz6eNGzcqKSlJGRkZCXEtr7XOixcv9vuZeLyeQ0V8RCAnJ0cul0v19fWhfYFAQAcOHAh7bTbRfP/99zp79qwyMzNjPcp1syxLq1ev1o4dO/T5558rJycn7Hh+fr5GjhwZdi1bWlp08uTJuLqW11rnQJqbmyUprq7n5fr6+hQMBhPmOg7k0hoHEo/XsLCwUEeOHFFzc3Nou+uuu/TYY4+F/p0I1/Ja6xzopet4vJ5Dxcsulzl37lxYfR4/flzNzc1KTU1Vdna2ysvL9fLLL2v69OnKycnRCy+8oKysLC1btix2Q0foamtMTU1VVVWVSktL5XK51NraqmeffVbTpk1TcXFxDKeOjNfrVV1dnT766COlpKSEXjN2Op0aPXq0nE6nVq5cqYqKCqWmpsrhcGjNmjXyeDyaO3dujKe/ftdaZ2trq+rq6vTAAw8oLS1Nhw8f1tq1azVv3rwBP/53I6qsrFRJSYmys7PV1dWluro6NTQ0aM+ePQlzHa+2xkS4hpKUkpIS9l4kSRo7dqzS0tJC+xPhWl5rnYlyPYcs1h+3udF88cUXlqR+W1lZmWVZ//u47QsvvGBlZGRYdrvdKiwstFpaWmI7dISutsbz589bCxcutCZOnGiNHDnSmjx5srVq1Sqrvb091mNHZKD1SbI2b94cOue///2v9ctf/tK69dZbrTFjxlgPPvigdfr06dgNPQjXWufJkyetefPmWampqZbdbremTZtm/frXv7b8fn9sB4/AL37xC2vy5MlWcnKyNXHiRKuwsND661//GjqeCNfxamtMhGt4JZd/5DQRruVAfrjORL6ekbBZlmWZjB0AAHBz4z0fAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGDU/wGGaTsPGkmD7QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.484646370979856 +- 15.454879075665907\n"
          ]
        }
      ],
      "source": [
        "# useful libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# use plt.hist to create histogram plot\n",
        "# YOUR CODE HERE\n",
        "num = 150\n",
        "trajs = []\n",
        "## fetch num of trajectories\n",
        "for idx in range(num):\n",
        "  trajs.append(collect_trajectory(policy_unif))\n",
        "## compute returns\n",
        "returns = []\n",
        "gamma = 0.99\n",
        "for idx in range(num):\n",
        "  returns.append(compute_return(trajs[idx], gamma))\n",
        "\n",
        "## output 1: histogram\n",
        "plt.hist(returns)\n",
        "plt.show()\n",
        "\n",
        "## output 2: mean of returns\n",
        "mean = sum(returns) / len(returns)\n",
        "std_err2 = ((sum([((x - mean) ** 2) for x in returns]) / len(returns))) ** 0.5 * 2\n",
        "\n",
        "print(\"{} +- {}\".format(mean, std_err2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBFD-MBhemrb"
      },
      "source": [
        "**Q4 (Optional)**: A linear policy has parameters $\\beta_1 \\in \\mathbb{R}^4$ and $\\beta_0 \\in \\mathbb{R}$. It computes $\\beta_1^\\top x - \\beta_0$, chooses action $+1$ if $\\beta_1^\\top x - \\beta_0 \\geq 0$, and chooses action $0$ otherwise.\n",
        "\n",
        "Write a random search learner. Randomly generate $10$ linear policies, evaluate them by sampling trajectories, and output the policy with the highest return.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "sDCNWfLncTdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d37dd3-f5d0-42ab-baa1-6dc802c536cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The highest return is 26.029962661171943.\n",
            "The corresponding linear policy is beta1 = [[-13.77163648 -44.19732374 -39.45709654 -21.04647266]], beta0 = [1.71331307]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "policy_num = 10\n",
        "param_record = []\n",
        "\n",
        "### Step 1: define linear policy\n",
        "def policy_linear(s):\n",
        "  ## randomly generate parameter pairs\n",
        "  policy = []\n",
        "  beta1 = np.random.rand(1,4)*100-50\n",
        "  beta0 = np.random.rand(1)*4-2\n",
        "  policy.append(beta1)\n",
        "  policy.append(beta0)\n",
        "  param_record.append(policy)\n",
        "  np.reshape(s,[-1,1])\n",
        "  judge = beta1 @ s + beta0\n",
        "  if judge >= 0:\n",
        "    a = 1\n",
        "  else:\n",
        "    a = 0\n",
        "  return a\n",
        "\n",
        "### Step 2: sampling trajectories\n",
        "trajs = []\n",
        "## fetch num of trajectories\n",
        "for idx in range(policy_num):\n",
        "  trajs.append(collect_trajectory(policy_linear))\n",
        "## compute returns\n",
        "returns = []\n",
        "gamma = 0.99\n",
        "for idx in range(policy_num):\n",
        "  returns.append(compute_return(trajs[idx], gamma))\n",
        "\n",
        "## Step 3: find highest return\n",
        "max = 0\n",
        "max_idx = 0\n",
        "for i in range(policy_num):\n",
        "  if returns[i] > max:\n",
        "    max = returns[i]\n",
        "    max_idx = i\n",
        "print(\"The highest return is {}.\".format(max))\n",
        "print(\"The corresponding linear policy is beta1 = {}, beta0 = {}\".format(param_record[max_idx][0], param_record[max_idx][1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoYJ55zCaPVA"
      },
      "source": [
        "**Instructions on converting iPython notebook to pdf**\n",
        "\n",
        "Please do not directly print the iPython notebook to pdf because it may have some issue if your code or text are too long."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONx9vjT8addX"
      },
      "source": [
        "Option 1: if you run the code locally with Jupyter Notebook or Jupyter Lab, there is an option to save to pdf from the menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOlgK0wXaVil"
      },
      "source": [
        "Option 2: if you run the code on Google colab. (You can delete the block below if you run code locally.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Qb8YPaYIW8k1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Here we use a script to generate pdf and save it to google drive.\n",
        "\n",
        "# After executing this cell, you will be asked to link to your GoogleDrive account.\n",
        "# Then, the pdf will be generated and saved to your GoogleDrive account and you need to go there to download;\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# install tex; first run may take several minutes\n",
        "! apt-get install texlive-xetex\n",
        "# file path and save location below are default; please change if they do not match yours\n",
        "! jupyter nbconvert --output-dir='/content/drive/MyDrive/' '/content/drive/MyDrive/Colab Notebooks/CS443RL_Assignment1.ipynb' --to pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkgV3wFWcI2y"
      },
      "source": [
        "Also feel free to use other methods as long as the converted file visually looks good."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}